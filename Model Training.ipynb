{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import plotly.graph_objects as go\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = pd.read_csv('C:/Users/sdole/PycharmProjects/Movie_Rating_Project/Original Dataset.csv')",
   "id": "c4c4be5521bce10e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Pre-Processing",
   "id": "3ba3cc432806c637"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Dropping rows where 'IMDB Score' is Null**",
   "id": "79e844821da34f6a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Keeps the relevant columns\n",
    "print(f'cols before: {df.columns}')\n",
    "df = df[['Title','Genre','Tags', 'Languages','Series or Movie','Runtime','Director','Writer','Actors', 'IMDb Score','Release Date','Summary']]\n",
    "print(f'After changing columns: {df.columns}')\n",
    "\n",
    "# How many nulls?\n",
    "print(f'How many nulls: {df.isnull().sum()}')\n",
    "\n",
    "# How many instances?\n",
    "print(f'How many instances: {df.shape[0]}')\n",
    "\n",
    "# How many nulls at 'IMDb Score'\n",
    "print(f'How many nulls in IMDb Score col: {df['IMDb Score'].isnull().sum()}')\n",
    "\n",
    "# Dropping rows with null value at IMDb Score col\n",
    "df.dropna(subset=['IMDb Score'], inplace=True)\n",
    "# number of instances after removing null value at IMDb Score col\n",
    "print(f'How many instances after dropping nulls in IMDb Score col: {df.shape[0]}')"
   ],
   "id": "c7d65807cf86050f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Dropping Duplicates**",
   "id": "c2c533abb21476d7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Duplicates\n",
    "# are there dup? \n",
    "print(f'are there duplicates? {df[\"Title\"].nunique() != len(df)}')\n",
    "\n",
    "# 1. adding the index as a column temporarily\n",
    "df.reset_index(inplace=True)\n",
    "df.rename(columns={'index': 'Original Index'}, inplace=True)\n",
    "\n",
    "# saving into a csv, duplicated rows that will be deleted\n",
    "duplicates = df[df.duplicated(subset=['Title', 'Release Date', 'Series or Movie'], keep='first')]\n",
    "duplicates.to_csv('deleted_duplicates.csv', index=False)\n",
    "\n",
    "# delete duplicates in df \n",
    "data_len_before = len(df)\n",
    "df.drop_duplicates(subset=['Title', 'Release Date', 'Series or Movie'], keep='first', inplace=True)\n",
    "data_len_after = len(df)\n",
    "print(f'Number of rows dropped: {data_len_before - data_len_after}')\n",
    "\n",
    "# Save df with the Original Index column to a new CSV file\n",
    "df.to_csv('after_dropping_dup_with_idx.csv', index=False)\n",
    "\n",
    "# Drop the 'Original Index' column and reset the index of the DataFrame\n",
    "df.drop(columns=['Original Index'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ],
   "id": "fcd97f03fd857de0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(f'Final number of instances: {df.shape[0]}')",
   "id": "411231ecde3f0f87",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Cardinality of variables \n",
    "print(f'Number of Unique Values in each column: {df.nunique()}')"
   ],
   "id": "88b84287729a4a4e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(df.describe())",
   "id": "de0aa1594044a6f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train Test Split",
   "id": "afc2c440df6ae903"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('IMDb Score', axis=1)  # Features\n",
    "y = df['IMDb Score']  # Target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shape of the resulting splits\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ],
   "id": "6bb7fc9ae58ed076",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Null Values",
   "id": "285cecc900f9a9c4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Lower case all categorical (except of: Title, and Summary)**",
   "id": "1415e48ec23daaad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_train.columns",
   "id": "2adc4c11b4ba8918",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#  TRAIN - lower\n",
    "categorical = ['Genre', 'Tags', 'Languages', 'Series or Movie', 'Runtime', 'Director', 'Writer', 'Actors']\n",
    "for column in categorical:\n",
    "    print(column, X_train[column].head())\n",
    "    X_train[column] = X_train[column].str.lower()\n",
    "    print(column, X_train[column].head())"
   ],
   "id": "73c4e1fdfb787b4b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TEST - lower\n",
    "categorical = ['Genre', 'Tags', 'Languages', 'Series or Movie', 'Runtime', 'Director', 'Writer', 'Actors']\n",
    "for column in categorical:\n",
    "    print(column, X_test[column].head())\n",
    "    X_test[column] = X_test[column].str.lower()\n",
    "    print(column, X_test[column].head())"
   ],
   "id": "34ed6339da11836f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Number of null values within each column - train\n",
    "print(f'number of nulls for each column after deleting all rows where target var (imdb rating) is null:  {X_train.isnull().sum()}')"
   ],
   "id": "d11d3c07ce43286c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Genre column**",
   "id": "9160dd3dfde375bf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# How many unique values before pre process\n",
    "print(X_train['Genre'].nunique())"
   ],
   "id": "888107e165cd5b4a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TRAIN - Sorting the Genres alphabetically\n",
    "def sort_genre(genre_col):\n",
    "    # if the row is none, return the row as is\n",
    "    if pd.isna(genre_col):\n",
    "        return genre_col\n",
    "    # Split the string by comma, strip any extra spaces, and sort the list\n",
    "    sorted_genres = sorted([genre.strip() for genre in genre_col.split(',')])\n",
    "    # Join the sorted list back into a string\n",
    "    return ', '.join(sorted_genres)\n",
    "\n",
    "\n",
    "# Apply the function to the 'Genre' column\n",
    "X_train['Genre'] = X_train['Genre'].apply(sort_genre)\n",
    "print(X_train['Genre'].nunique())\n",
    "\n",
    "# Calculate the percentage of occurrences of each category (combination)\n",
    "num_rows = len(X_train)\n",
    "genre_percentage = X_train['Genre'].value_counts(dropna=False) / num_rows * 100\n",
    "genre_percentage = genre_percentage.sort_values(ascending=False)\n",
    "print(genre_percentage)\n",
    "\n",
    "\n",
    "top_15_genres = genre_percentage.head(15)\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(12, 8))\n",
    "ax = top_15_genres.plot(kind='bar', color='skyblue', edgecolor='white')\n",
    "plt.title('Top 10 Most Frequent Genre Combinations')\n",
    "plt.xlabel('Genre Combination')\n",
    "plt.ylabel('Percentage')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Adding percentage labels on top of bars\n",
    "for i, percentage in enumerate(top_15_genres):\n",
    "    ax.text(i, percentage + 0.1, f'{percentage:.2f}%', ha='center', va='bottom')\n",
    "    "
   ],
   "id": "f920cf5de884463e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TEST - Sorting the Genres alphabetically# Apply the function to the 'Genre' column\n",
    "X_test['Genre'] = X_test['Genre'].apply(sort_genre)\n",
    "print(X_test['Genre'].nunique())\n"
   ],
   "id": "e7d7463977737f46",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# PLOT - Percentage of occurrences of each unique genre\n",
    "\n",
    "from collections import Counter\n",
    "# Function to calculate genre percentages\n",
    "def calculate_genre_percentages(df, column_name):\n",
    "    # Extract all genres into a single list\n",
    "    genres = df[column_name].dropna().str.split(',').sum()\n",
    "    # Strip whitespace from each genre\n",
    "    genres = [genre.strip() for genre in genres]\n",
    "    # Count the occurrences of each genre\n",
    "    genre_counts = Counter(genres)\n",
    "    # Calculate the percentage of each genre\n",
    "    total_genres = sum(genre_counts.values())\n",
    "    genre_percentages = {genre: (count / total_genres) * 100 for genre, count in genre_counts.items()}\n",
    "    # Convert to DataFrame for sorting\n",
    "    genre_percentages_df = pd.DataFrame(list(genre_percentages.items()), columns=['Genre', 'Percentage'])\n",
    "    # Sort by percentage from highest to lowest\n",
    "    genre_percentages_df = genre_percentages_df.sort_values(by='Percentage', ascending=False).reset_index(drop=True)\n",
    "    return genre_percentages_df\n",
    "\n",
    "# Calculate and display the genre percentages\n",
    "genre_percentages_X_train = calculate_genre_percentages(X_train, 'Genre')\n",
    "print(genre_percentages_X_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(20,10))\n",
    "ax = genre_percentages_X_train.head(15).plot(x = 'Genre',y='Percentage', kind='bar', color='skyblue', edgecolor='white')\n",
    "plt.title('Top 10 Most Frequent Genre')\n",
    "plt.xlabel('Genre Combination')\n",
    "plt.ylabel('Percentage')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Adding percentage labels on top of bars\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height():.2f}%', \n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                ha='center', va='baseline', \n",
    "                xytext=(0, 10), \n",
    "                textcoords='offset points')\n",
    "\n",
    "plt.show()"
   ],
   "id": "a37f28a4373ffb5a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "steps: \n",
    "1. Pre-process 'Tags' - lower case, keep ascii only, tokenize, lemmatize, kees as list of words \n",
    "2. Create a list of unique values in the column Genre and find the most common genre \n",
    "3.  Loop through the rows where 'genre' == Null, check in 'Tags' if there is a word that matches to one of the words in the list of unique geners, if no found, copy the first word, if tags also empty then fill genre with the most common genre.\n",
    "4. Delete 'Tags' column"
   ],
   "id": "756a0c66b92d4e06"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TRAIN - 1. Pre-Process Tags column \n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "exclude_chars = {'@', '\"', '#', '$', '%', '&', ',', '}', '{', '(', ')', '*', '^'}\n",
    "ascii_chars_to_keep = set(string.printable) - exclude_chars\n",
    "print(X_train['Tags'].head())\n",
    "\n",
    "def pre_process_tags(text):\n",
    "    # if text is not a string (NAN or None)\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    tokens = word_tokenize(text)\n",
    "    # Keeping only ascii chars and lower case\n",
    "    processed_tokens = []\n",
    "    for token in tokens:\n",
    "        token = ''.join([char.lower() for char in token if char in ascii_chars_to_keep])\n",
    "        token = token.strip()\n",
    "        if token:\n",
    "            processed_tokens.append(token)\n",
    "    # lemmatize each token\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    corrected_tokens = [lemmatizer.lemmatize(token) for token in processed_tokens if token]\n",
    "    \n",
    "    return corrected_tokens\n",
    "\n",
    "            \n",
    "X_train['Tags'] = X_train['Tags'].apply(pre_process_tags)\n",
    "\n",
    "\n",
    "print(X_train['Tags'].head())"
   ],
   "id": "e4d765063cef51bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TEST\n",
    "print(X_test['Tags'].head())\n",
    "X_test['Tags'] = X_test['Tags'].apply(pre_process_tags)\n",
    "print(X_test['Tags'].head())"
   ],
   "id": "6bd687ac4c4f2a45",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TRAIN - 2. making a list of all unique Genres\n",
    "unique_genres = set()\n",
    "genre_count = {}\n",
    "for genres in X_train['Genre'].dropna():\n",
    "    for word in genres.split(','):\n",
    "        word = word.lower().strip()\n",
    "        unique_genres.add(word)\n",
    "        if word in genre_count:\n",
    "            genre_count[word] += 1\n",
    "        else:\n",
    "            genre_count[word] = 1\n",
    "\n",
    "# Find the most common genre\n",
    "genre_mode = max(genre_count, key=genre_count.get)\n",
    "print(f'Most common Genre: {genre_mode}')\n",
    "\n",
    "\n",
    "# 3. Function to fill missing genres based on tags and unique_genres\n",
    "def fill_missing_genres(dataframe, genres_set, most_common_genre):\n",
    "    # iterate over each row \n",
    "    for idx, row in dataframe.iterrows():\n",
    "        # if genre is null\n",
    "        if pd.isna(row['Genre']):\n",
    "            # if tags is not empty list - loop for each word in genres set, if the word in tags, copy to genre null\n",
    "            if row['Tags']:\n",
    "                found_genre = False\n",
    "                for word in genres_set:\n",
    "                    if word in row['Tags']:\n",
    "                        dataframe.at[idx, 'Genre'] = word\n",
    "                        found_genre = True\n",
    "                        break\n",
    "                if not found_genre:\n",
    "                    dataframe.at[idx, 'Genre'] = row['Tags'][0]\n",
    "            # if tags is also empty, fill null with common genre\n",
    "            else:\n",
    "                dataframe.at[idx, 'Genre'] = most_common_genre\n",
    "    # Drop the 'Tags' column after filling in the genres\n",
    "    dataframe.drop(columns=['Tags'], inplace=True)\n",
    "    return dataframe\n",
    "\n",
    "# Call the function\n",
    "X_train = fill_missing_genres(X_train, unique_genres, genre_mode)"
   ],
   "id": "b42db0289bd24c73",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TEST\n",
    "X_test = fill_missing_genres(X_test, unique_genres, genre_mode)"
   ],
   "id": "b149277ce0147190",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# check now if all good \n",
    "print(X_train.isnull().sum())"
   ],
   "id": "d5b3d8974037e8de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Language**\n",
   "id": "f238444261513598"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "steps: \n",
    "1. Pre-process language - for each row split the value into a list and save only the first language\n",
    "2. find mode in column - find the mode language ('language_mode')\n",
    "3. Create actor language dict - returns a dictionary, each key is an actor, and each value is the most common language of that actor \n",
    "4. filling nulls language - gets a dictionary and a language mode. Fill null by the dictionary, if key not found, complete by the mode."
   ],
   "id": "b130557ac589d86c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1. LANGUAGE COL WITH 1 VAL ONLY: gets a column language, and keeps the first value in each row \n",
    "def pre_process_language(text_language):\n",
    "    # if the value is not nun or none then do that. else, skip \n",
    "    if isinstance(text_language, str):\n",
    "        language_list = text_language.split(',')\n",
    "        return language_list[0].strip()\n",
    "    else: \n",
    "        return text_language\n",
    "\n",
    "X_train['Languages'] = X_train['Languages'].apply(pre_process_language)\n",
    "\n",
    "# 2. FIND LANGUAGE MODE: calculates the most common val in language (mode)\n",
    "def find_mode_in_col(col):\n",
    "    mode_result = col.mode()\n",
    "    if not mode_result.empty:\n",
    "        return mode_result.iloc[0]\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "language_mode = find_mode_in_col(X_train['Languages'])\n",
    "print(language_mode)\n",
    "\n",
    "\n",
    "# 3. CREATE A DICT: {'CHRIS': ENGLISH, SPANISH, ETC.}\n",
    "# Populate the dictionary with known first languages for each actor\n",
    "# Iterate through all rows in the DataFrame\n",
    "def create_actor_language_dict(dataframe):\n",
    "    # Create a dictionary to hold the first languages for each actor\n",
    "    dict_actors = {}\n",
    "    for index, row in dataframe.iterrows():\n",
    "        if isinstance(row['Languages'], str):   # Check if the 'Languages' field is not NaN and not 'null'\n",
    "            # Split the actors and languages and trim whitespace from each element\n",
    "            actors = [actor.strip() for actor in ([] if type(row['Actors'])!=str else row['Actors'].split(','))]  # Trim whitespace from each actor\n",
    "            # Get the first language (only one language per row now)\n",
    "            first_language = row['Languages'].strip()\n",
    "    \n",
    "            if actors and first_language:\n",
    "              # for each actor in this row \n",
    "              for actor in actors:\n",
    "                actor = actor.strip()\n",
    "                if actor not in dict_actors:\n",
    "                    dict_actors[actor] = [first_language]\n",
    "                else: \n",
    "                    dict_actors[actor].append(first_language)\n",
    "    # updating the dictionary to store the mode language for each key (actor) \n",
    "    for actor, languages in dict_actors.items():\n",
    "            mode_language_per_actor  = statistics.mode(languages)\n",
    "            dict_actors[actor] = mode_language_per_actor\n",
    "    \n",
    "    return dict_actors\n",
    "# calling the function \n",
    "actor_language_dict = create_actor_language_dict(X_train)     \n",
    "\n",
    "\n",
    "# 4. filling in nulls of language rows with the actors dictionary\n",
    "def filling_nulls_language(dataframe, actor_language_dict):\n",
    "    for idx, row in dataframe.iterrows():\n",
    "        # for each null row in language\n",
    "        if pd.isna(row['Languages']):\n",
    "            # if actor is not null \n",
    "            if isinstance(row['Actors'], str):\n",
    "                # stor the actors name \n",
    "                actor_key = row['Actors'].split(',')[0].strip().lower()\n",
    "                # if the actors name is a key in dict then fill language with the value of the key \n",
    "                if actor_key in actor_language_dict:\n",
    "                    dataframe.at[idx, 'Languages'] = actor_language_dict[actor_key]\n",
    "                else: \n",
    "                    dataframe.at[idx, 'Languages'] = language_mode\n",
    "            else: \n",
    "                dataframe.at[idx, 'Languages'] = language_mode\n",
    "\n",
    "filling_nulls_language(X_train, actor_language_dict)\n"
   ],
   "id": "be8c19693c2bec1a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TEST\n",
    "# 1. keeps the first language in each row \n",
    "X_test['Languages'] = X_test['Languages'].apply(pre_process_language)\n",
    "\n",
    "# 2. filling nulls with the actor dictionary that we made in train\n",
    "filling_nulls_language(X_test, actor_language_dict)"
   ],
   "id": "d28ff7d00dbc1b96",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_train.isnull().sum()",
   "id": "e7f329fd091d3ffb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_test.isnull().sum()",
   "id": "494de7c4e5a96f96",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**director, writer, actors, release date - Random sampling imputation method**",
   "id": "4d954e1646a742c0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "steps: \n",
    "1. pre-process_category - gets a value in a column. if the value is not null, split the value into a list of words, by a comma. i.e 'chris brown, danna fox' returns 'chris brown'\n",
    "2. fill null imputation - gets a column and a dataframe and filling nulls while keeping the distribution of the variable"
   ],
   "id": "7a2c9246c195ecd2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1. pre-process category by keeping the first value in each row\n",
    "def pre_process_category(value):\n",
    "    # if the value is not nun or none then do that. else, skip \n",
    "    if isinstance(value, str):\n",
    "        # lower \n",
    "        value.lower()\n",
    "        # convert into a list of writers\n",
    "        list_val = value.split(',')\n",
    "        return list_val[0].strip()\n",
    "    else: \n",
    "        return value"
   ],
   "id": "f106fd18bde1e9eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 2. random sampling imputation- filling nulls \n",
    "def fill_null_with_category(dataframe, column):\n",
    "    # Get the proportion of each category in the column\n",
    "    value_counts = dataframe[column].value_counts(normalize=True)\n",
    "    # Generate a list with missing values in the specified column\n",
    "    null_indices = dataframe.index[dataframe[column].isnull()].tolist()\n",
    "    # Fill in missing values with the proportion of each category\n",
    "    dataframe.loc[null_indices, column] = np.random.choice(value_counts.index, size=len(null_indices), p=value_counts.values)\n",
    "    return value_counts"
   ],
   "id": "259fd63b632b0f1e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Director\n",
    "X_train['Director'] = X_train['Director'].apply(pre_process_category)\n",
    "Director_distribution = fill_null_with_category(X_train, 'Director')\n",
    "X_train['Director'].isnull().sum()"
   ],
   "id": "6ab0937af8dfd354",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Writer\n",
    "X_train['Writer'] = X_train['Writer'].apply(pre_process_category)\n",
    "Writer_distribution = fill_null_with_category(X_train, 'Writer')\n",
    "X_train['Writer'].isnull().sum()"
   ],
   "id": "36e27e3163a4ca9b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# actors \n",
    "X_train['Actors'] = X_train['Actors'].apply(pre_process_category)\n",
    "Actors_distribution = fill_null_with_category(X_train, 'Actors')\n",
    "X_train['Actors'].isnull().sum()"
   ],
   "id": "f79dbfc318cd7960",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# release date\n",
    "X_train['Release Date'] = X_train['Release Date'].apply(pre_process_category)\n",
    "Release_Date_distribution = fill_null_with_category(X_train, 'Release Date')\n",
    "X_train['Release Date'].isnull().sum()"
   ],
   "id": "52961c7d6b6b3712",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_train.isnull().sum()",
   "id": "e830d38d61fc97ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# How many unique values each column has now? \n",
    "column_info = []\n",
    "for col in X_train.columns:\n",
    "    col_name = col \n",
    "    col_unique = X_train[col].nunique()\n",
    "    \n",
    "        # adding the columns \n",
    "    column_info.append({\n",
    "        'Column Name': col_name,\n",
    "        'Unique Values': col_unique,\n",
    "    })\n",
    "\n",
    "\n",
    "column_info_df = pd.DataFrame(column_info)\n",
    "\n",
    "# plot the table \n",
    "fig = go.Figure(data=[go.Table(\n",
    "    header=dict(values=list(column_info_df.columns),\n",
    "                fill_color= '#636EFA',\n",
    "                align='left',\n",
    "                font=dict(color='black', size=15)),\n",
    "    cells=dict(values=[column_info_df['Column Name'], column_info_df['Unique Values']],\n",
    "               fill_color='lavender',\n",
    "               align='left',\n",
    "               height=25,\n",
    "               font=dict(color='black', size=13)))\n",
    "])\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(template='plotly_white', width=550, height= 550)\n",
    "\n",
    "# Show the table\n",
    "fig.show()\n"
   ],
   "id": "d510ee4a40193e11",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TEST \n",
    "# New function to use the value counts for the test set\n",
    "def fill_null_with_category_test_set(dataframe, column, value_counts):\n",
    "    # Generate a list with missing values in the specified column\n",
    "    null_indices = dataframe.index[dataframe[column].isnull()].tolist()\n",
    "    # Fill in missing values with the proportion of each category from the training set\n",
    "    dataframe.loc[null_indices, column] = np.random.choice(value_counts.index, size=len(null_indices), p=value_counts.values)"
   ],
   "id": "a45fb0bfabce0ca7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# director\n",
    "X_test['Director'] = X_test['Director'].apply(pre_process_category)\n",
    "fill_null_with_category_test_set(X_test, 'Director', Director_distribution)\n",
    "X_test['Director'].isnull().sum()\n",
    "\n",
    "# Writer\n",
    "X_test['Writer'] = X_test['Writer'].apply(pre_process_category)\n",
    "fill_null_with_category_test_set(X_test, 'Writer', Writer_distribution)\n",
    "X_test['Writer'].isnull().sum()\n",
    "\n",
    "# actors \n",
    "X_test['Actors'] = X_test['Actors'].apply(pre_process_category)\n",
    "fill_null_with_category_test_set(X_test, 'Actors', Actors_distribution)\n",
    "X_test['Actors'].isnull().sum()\n",
    "\n",
    "# release date\n",
    "X_test['Release Date'] = X_test['Release Date'].apply(pre_process_category)\n",
    "fill_null_with_category_test_set(X_test, 'Release Date', Release_Date_distribution)\n",
    "X_test['Release Date'].isnull().sum()"
   ],
   "id": "6f056eaa72c25bb4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_test.isnull().sum()",
   "id": "8057d3069eeff43a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Feature Representation",
   "id": "78597eee555c7ca8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. the function gest a dataframe, a column to encode, and a set of unique values within the column \n",
    "2. first we iterate over the set, and create a new column with the name of each value \n",
    "3. then we loop through the rows. for each row we insert the values within the row into a list \n",
    "4. for each value in this list if the value in the set of unique values, I want to put 1 in the corresponding column "
   ],
   "id": "d85449fc12378bb4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def feature_representation_one_hot(dataframe, column_to_encode, unique_values_set):\n",
    "    \"\"\"\n",
    "    Perform one-hot encoding on a specified column in the dataframe based on the unique values provided.\n",
    "    \n",
    "    Args:\n",
    "    dataframe (pd.DataFrame): The dataframe to transform.\n",
    "    column (str): The name of the column to one-hot encode.\n",
    "    unique_values (set): The set of unique values to create binary columns for.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: The transformed dataframe with one-hot encoded columns.\n",
    "    \"\"\"\n",
    "    # Initialize binary columns for each unique value\n",
    "    for value in unique_values_set:\n",
    "        column_name = f\"{column_to_encode}_{value}\"\n",
    "        dataframe[column_name] = 0\n",
    "    \n",
    "    for idx, row in dataframe.iterrows():\n",
    "        # Get the value(s) in the specified column\n",
    "        values_list = row[column_to_encode].lower().split(',')\n",
    "        # For each value, set the corresponding binary column to 1\n",
    "        for value in values_list:\n",
    "            if value in unique_values_set:\n",
    "                column_name = f\"{column_to_encode}_{value}\"\n",
    "                dataframe.at[idx, column_name] = 1\n",
    "    \n",
    "    dataframe.drop(columns=[column_to_encode], inplace=True)\n",
    "    return dataframe"
   ],
   "id": "4553d33531fd2f8c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Genre**",
   "id": "eafebb22a6c67bb4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(X_train.columns)\n",
    "X_train = feature_representation_one_hot(X_train, 'Genre', unique_genres)\n",
    "print(X_train.columns)"
   ],
   "id": "90a2d030076efacc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TEST \n",
    "print(X_test.columns)\n",
    "X_test = feature_representation_one_hot(X_test, 'Genre', unique_genres)\n",
    "print(X_test.columns)\n",
    "print(X_test.isnull().sum())"
   ],
   "id": "c750cc8e2fbab4b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ],
   "id": "69864dc531fc80f8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Director, Writer, Actors**",
   "id": "81cd837a75e60551"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "taking the top 15, the rest is 'other' ",
   "id": "8107184332bc7f5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Director**",
   "id": "be686bda83e4c283"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "director_counts = X_train['Director'].value_counts()\n",
    "total_rows = len(X_train)\n",
    "director_percentage = ((director_counts / total_rows) * 100).sort_values(ascending=False)\n",
    "director_percentage_set = set(director_percentage.index)\n",
    "print(director_percentage)\n",
    "\n",
    "top_directors = director_percentage.head(30)\n",
    "plt.figure(figsize=(12, 8))\n",
    "bars = plt.bar(top_directors.index, top_directors.values, color='orange')\n",
    "\n",
    "# Adding the percentage labels on top of each bar\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.005, f'{yval:.2f}%', ha='center', va='bottom')\n",
    "\n",
    "plt.xlabel('Director')\n",
    "plt.ylabel('Percentage')\n",
    "plt.title('Top Director by Percentage')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('Director distribution.png', facecolor='white', edgecolor='white')\n",
    "# Display the plot\n",
    "plt.show()"
   ],
   "id": "48444e15b6e7fa39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# convert every value in director column, to other, if it is not in set\n",
    "top_15_directors_set = set(director_percentage.head(15).index)\n",
    "\n",
    "def replace_non_top_director(dataframe, top_director_set):\n",
    "    for idx, row in dataframe.iterrows():\n",
    "        if row['Director'] not in top_director_set:\n",
    "            dataframe.at[idx, 'Director'] = \"Other\"\n",
    "    return dataframe\n",
    "\n",
    "X_train = replace_non_top_director(X_train, top_15_directors_set)"
   ],
   "id": "2e9eb7afb67aa8ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check that there are 16 unique values\n",
    "X_train['Director'].nunique()"
   ],
   "id": "d227b2aa9b1beee0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create the set of unique directors\n",
    "directors_set = set(X_train['Director'].unique()) - {'Other'}\n",
    "directors_set"
   ],
   "id": "9015b332c9313dc7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train = X_train.copy()\n",
    "X_test = X_test.copy()\n",
    "print(X_train['Director'])"
   ],
   "id": "ea6909a2171af86a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(X_test['Director'])",
   "id": "dd552c1cd580305a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TRAIN \n",
    "print(X_train.columns)\n",
    "X_train = feature_representation_one_hot(X_train, 'Director', directors_set)\n",
    "print(X_train.columns)\n",
    "print(X_train.isnull().sum())"
   ],
   "id": "3c0cbed70b09a2ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(X_test['Director'])",
   "id": "8b968986e825ed23",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TEST\n",
    "print(X_test.columns)\n",
    "X_test = feature_representation_one_hot(X_test, 'Director', directors_set)\n",
    "print(X_test.columns)\n",
    "print(X_test.isnull().sum())\n",
    "print(len(X_test.columns))"
   ],
   "id": "95141e489d2da94f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(len(X_test.columns))\n",
   "id": "291c8e8e1c94c6f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Writer**",
   "id": "8a2d7f736916c3be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# calculate the percentage of each writer \n",
    "writer_counts = X_train['Writer'].value_counts()\n",
    "total_rows = len(X_train)\n",
    "writer_percentage = ((writer_counts / total_rows) * 100).sort_values(ascending=False)\n",
    "print(writer_percentage)\n",
    "top_15_writers = writer_percentage.head(25)\n",
    "plt.figure(figsize=(12, 8))\n",
    "bars = plt.bar(top_15_writers.index, top_15_writers.values, color='orange')\n",
    "\n",
    "# Adding the percentage labels on top of each bar\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.005, f'{yval:.2f}%', ha='center', va='bottom')\n",
    "\n",
    "plt.xlabel('Writers')\n",
    "plt.ylabel('Percentage')\n",
    "plt.title('Top 15 Writers by Percentage')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ],
   "id": "aa6cc6ddde0b3bbd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# convert every value in writer column, to other, if it is not in set\n",
    "top_15_writers_set = set(writer_percentage.head(15).index)\n",
    "type(top_15_writers_set)\n",
    "\n",
    "def replace_non_top_writers(dataframe, top_writers_set):\n",
    "    for idx, row in dataframe.iterrows():\n",
    "        if row['Writer'] not in top_writers_set:\n",
    "            dataframe.at[idx, 'Writer'] = \"Other\"\n",
    "    return dataframe\n",
    "\n",
    "X_train = replace_non_top_writers(X_train, top_15_writers_set)"
   ],
   "id": "416198ef01875d63",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create the set of unique directors\n",
    "Writers_set = set(X_train['Writer'].unique()) - {'Other'}\n",
    "Writers_set"
   ],
   "id": "b9c1a29a0ee27a8c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TRAIN \n",
    "print(X_train.columns)\n",
    "X_train = feature_representation_one_hot(X_train, 'Writer', Writers_set)\n",
    "print(X_train.columns)\n",
    "print(X_train.isnull().sum())"
   ],
   "id": "5b981b9263e1ef43",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TEST\n",
    "print(X_test.columns)\n",
    "X_test = feature_representation_one_hot(X_test, 'Writer', Writers_set)\n",
    "print(X_test.columns)\n",
    "print(X_test.isnull().sum())\n",
    "print(len(X_test.columns))"
   ],
   "id": "68d2a3198246ead7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(Writers_set)",
   "id": "3a78a1f9b7863b31",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Actors**",
   "id": "d4ae85dba63ca785"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "actors_counts = X_train['Actors'].value_counts()\n",
    "total_rows = len(X_train)\n",
    "actors_percentage = ((actors_counts / total_rows) * 100).sort_values(ascending=False)\n",
    "actors_percentage_set = set(actors_percentage.index)\n",
    "print(actors_percentage)\n",
    "\n",
    "top_actors = actors_percentage.head(45)\n",
    "plt.figure(figsize=(12, 8))\n",
    "bars = plt.bar(top_actors.index, top_actors.values, color='orange')\n",
    "\n",
    "# Adding the percentage labels on top of each bar\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.005, f'{yval:.2f}%', ha='center', va='bottom')\n",
    "\n",
    "plt.xlabel('Director')\n",
    "plt.ylabel('Percentage')\n",
    "plt.title('Top Director by Percentage')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ],
   "id": "dafe2456b8aa09ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# convert every value in director column, to other, if it is not in set\n",
    "top_15_actors_set = set(actors_percentage.head(15).index)\n",
    "type(top_15_writers_set)\n",
    "\n",
    "def replace_non_top_director(dataframe, top_actors_set):\n",
    "    for idx, row in dataframe.iterrows():\n",
    "        if row['Actors'] not in top_actors_set:\n",
    "            dataframe.at[idx, 'Actors'] = \"Other\"\n",
    "    return dataframe\n",
    "\n",
    "X_train = replace_non_top_director(X_train, top_15_actors_set)"
   ],
   "id": "348c4d3dbeff5419",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create the set of unique directors\n",
    "actor_set = set(X_train['Actors'].unique()) - {'Other'}\n",
    "actor_set"
   ],
   "id": "974597980882903",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TRAIN \n",
    "print(X_train.columns)\n",
    "X_train = feature_representation_one_hot(X_train, 'Actors', actor_set)\n",
    "print(X_train.columns)\n",
    "print(X_train.isnull().sum())"
   ],
   "id": "5e3e797338b343a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(X_test['Actors'])",
   "id": "dbd49aaf20b420fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TRAIN \n",
    "print(X_test.columns)\n",
    "X_test = feature_representation_one_hot(X_test, 'Actors', actor_set)\n",
    "print(X_test.columns)\n",
    "print(X_test.isnull().sum())"
   ],
   "id": "7158e0571fd1445b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Language**",
   "id": "24ac5486072e2455"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "language_count = X_train['Languages'].value_counts()\n",
    "total_rows = len(X_train)\n",
    "Language_percentage_sorted = ((language_count / total_rows) * 100).sort_values(ascending=False)\n",
    "Language_percentage_sorted_set = set(Language_percentage_sorted.index)\n",
    "print(Language_percentage_sorted)\n",
    "\n",
    "top_languages = Language_percentage_sorted.head(20)\n",
    "plt.figure(figsize=(12, 8))\n",
    "bars = plt.bar(top_languages.index, top_languages.values, color='blue')\n",
    "\n",
    "# Adding the percentage labels on top of each bar\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.005, f'{yval:.2f}%', ha='center', va='bottom')\n",
    "\n",
    "plt.xlabel('Languages')\n",
    "plt.ylabel('Percentage')\n",
    "plt.title('Top Languages by Percentage')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('Language distribution.png', facecolor='white', edgecolor='white')\n",
    "# Display the plot\n",
    "plt.show()"
   ],
   "id": "1f58d435c28e5e85",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "Language_percentage_sorted_set",
   "id": "71b82e66ba098e16",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# convert every value in director column, to other, if it is not in set\n",
    "top_15_language_set = set(Language_percentage_sorted.head(15).index)\n",
    "type(top_15_language_set)\n",
    "\n",
    "def replace_non_top_language(dataframe, top_language_set):\n",
    "    for idx, row in dataframe.iterrows():\n",
    "        if row['Languages'] not in top_language_set:\n",
    "            dataframe.at[idx, 'Languages'] = \"Other\"\n",
    "    return dataframe\n",
    "\n",
    "X_train = replace_non_top_language(X_train, top_15_language_set)"
   ],
   "id": "b36a70a8429fa2c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create the set of unique directors\n",
    "Languages_set = set(X_train['Languages'].unique()) - {'Other'}\n",
    "Languages_set"
   ],
   "id": "65fc0859b643b1f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TRAIN \n",
    "print(X_train.columns)\n",
    "X_train = feature_representation_one_hot(X_train, 'Languages', Languages_set)\n",
    "print(X_train.columns)\n",
    "print(X_train.isnull().sum())"
   ],
   "id": "e5c6be8575f2d242",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TRAIN \n",
    "print(X_test.columns)\n",
    "X_test = feature_representation_one_hot(X_test, 'Languages', Languages_set)\n",
    "print(X_test.columns)\n",
    "print(X_test.isnull().sum())"
   ],
   "id": "c68bf43a529151ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Runtime**",
   "id": "c8314cbd3c09e373"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TRAIN\n",
    "# Represents as an ordinal variable\n",
    "\n",
    "runtime_order = ['< 30 minutes', '30-60 mins', '1-2 hour', '> 2 hrs']\n",
    "runtime_mapping = {runtime: index for index, runtime in enumerate(runtime_order)}\n",
    "\n",
    "\n",
    "# Apply the mapping to the Runtime column\n",
    "X_train['Runtime'] = X_train['Runtime'].map(runtime_mapping)\n",
    "\n",
    "print(X_train['Runtime'].nunique())\n",
    "print(X_train['Runtime'].unique())"
   ],
   "id": "48537d29693e0ee5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TEST\n",
    "# Apply the same mapping to the Runtime column in the test set\n",
    "X_test['Runtime'] = X_test['Runtime'].map(runtime_mapping)\n",
    "print(X_test['Runtime'].nunique())\n",
    "print(X_test['Runtime'].unique())"
   ],
   "id": "cad1a48554ed1c06",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**release date**",
   "id": "d64056185dc8a159"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TRAIN\n",
    "# Convert to date type\n",
    "X_train['Release Date'] = pd.to_datetime(X_train['Release Date'])\n",
    "\n",
    "# Extract year, month, and day using the dt accessor\n",
    "X_train['Released_Year'] = X_train['Release Date'].dt.year\n",
    "X_train['Released_Month'] = X_train['Release Date'].dt.month\n",
    "# X_train['Released_Day'] = X_train['Release Date'].dt.day\n",
    "\n",
    "# Drop the 'Release Date' column\n",
    "X_train.drop(columns=['Release Date'], inplace=True)\n",
    "\n",
    "# print columns to check\n",
    "X_train.columns"
   ],
   "id": "8661fcdeb518a9e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# check datatype of releases  \n",
    "print(X_train[['Released_Year', 'Released_Month']].dtypes)"
   ],
   "id": "6dc86e998a0c24df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TEST\n",
    "# Convert to date type\n",
    "X_test['Release Date'] = pd.to_datetime(X_test['Release Date'])\n",
    "\n",
    "# Extract year, month, and day using the dt accessor\n",
    "X_test['Released_Year'] = X_test['Release Date'].dt.year\n",
    "X_test['Released_Month'] = X_test['Release Date'].dt.month\n",
    "# X_test['Released_Day'] = X_test['Release Date'].dt.day\n",
    "\n",
    "# Drop the 'Release Date' column\n",
    "X_test.drop(columns=['Release Date'], inplace=True)\n",
    "\n",
    "# print columns to check\n",
    "X_test.columns"
   ],
   "id": "c6b1391468103a2e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "c10ec34888c807a4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Series or Movie**",
   "id": "706c87b4cee7db9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TRAIN\n",
    "# Gets a dataframe, column to encode and positive (which category will encode as 1) \n",
    "def binary_encode_column(dataframe, column_to_encode, positive_value):\n",
    "    # Create a binary column indicating whether the value is the positive value (e.g., 'movie')\n",
    "    dataframe[column_to_encode + '_' + positive_value] = (dataframe[column_to_encode] == positive_value).astype(int)\n",
    "    \n",
    "    # Drop the original column\n",
    "    dataframe = dataframe.drop(column_to_encode, axis=1)\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "# Example usage:\n",
    "# Assuming df is your DataFrame\n",
    "X_train = binary_encode_column(X_train, 'Series or Movie', 'movie')"
   ],
   "id": "92ce6de7fbd597ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_train[\"Series or Movie_movie\"]",
   "id": "7e4acd5df5409946",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TEST\n",
    "X_test = binary_encode_column(X_test, 'Series or Movie', 'movie')"
   ],
   "id": "2b9ee96b5e3f8cba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(X_test.columns)",
   "id": "6a15bc6841623210",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Feature Extraction",
   "id": "93172fbd5c64f58e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Summary - Count Words**",
   "id": "5fc7fd396370ae20"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "\n",
    "#text = df['Summary']\n",
    "def word_count(text):\n",
    " if isinstance(text, str):  # Check if the value is a string\n",
    "   text = text.replace('-', ' ')\n",
    "   cleaned_text = re.sub(r'[^\\w\\s]', '', text)\n",
    "   return len(cleaned_text.split())\n",
    " else:\n",
    "     return 0  # Return 0 for non-string values\n",
    "\n",
    "\n",
    "# Apply the word_count function to the 'Summary' column\n",
    "X_train['Summary_length'] = X_train['Summary'].apply(word_count)\n",
    "\n",
    "\n",
    "#df.head(10)\n",
    "# cheking the data type \n",
    "X_train['Summary_length'].dtype"
   ],
   "id": "ac5df137f6ab0281",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TEST \n",
    "X_test['Summary_length'] = X_test['Summary'].apply(word_count)\n"
   ],
   "id": "3f07af70d35ab30f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(X_train.columns)\n",
    "print(X_test.columns)\n",
    "print(len(X_test.columns)==len(X_train.columns))"
   ],
   "id": "f941e4ce914b3cd2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Summary - Sentiment Analysis**",
   "id": "797064bb79b67fa7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "not removing stop words because they are meaningful in sentiment analysis - for example: not, is a stop word, and we dont remove punctuation marks because they are in the Vadar lexicon ",
   "id": "ed0f02ffc4f4d317"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# print the vocabulary \n",
    "analyzer.lexicon"
   ],
   "id": "c045178b7386396a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Gets a text, extract pos, neg, neu scores \n",
    "def sentiment_scores(text):\n",
    "    text.lower()\n",
    "    scores = analyzer.polarity_scores(str(text))\n",
    "    return pd.Series([scores['pos'], scores['neg'], scores['neu']])\n",
    "\n",
    "\n",
    "X_train[['positive', 'negative', 'neutral']] = X_train['Summary'].apply(sentiment_scores)\n",
    "print(X_train[['positive', 'negative', 'neutral']].head())"
   ],
   "id": "3f12e1200d6832a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# check that the columns where added \n",
    "X_train.columns "
   ],
   "id": "c182dee7a5b9581b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# print an example of a sentence and its scores \n",
    "example = X_train[['Summary','positive', 'negative', 'neutral']].head(5)\n",
    "example"
   ],
   "id": "5d4bd63c536ddcf8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TEST\n",
    "X_test[['positive', 'negative', 'neutral']] = X_test['Summary'].apply(sentiment_scores)\n"
   ],
   "id": "1b67bf7f3cd77d47",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(X_train.columns)\n",
    "print(X_test.columns)\n",
    "print(len(X_test.columns)==len(X_train.columns))"
   ],
   "id": "2d8fd0df59ff176d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Dropping Title and Summary columns**",
   "id": "5e10cf03deb0fda3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TRAIN \n",
    "X_train.drop('Title', axis=1, inplace=True)\n",
    "X_train.drop('Summary', axis=1, inplace=True)"
   ],
   "id": "4ecc4d08fcee3fd7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TEST \n",
    "X_test.drop('Title', axis=1, inplace=True)\n",
    "X_test.drop('Summary', axis=1, inplace=True)"
   ],
   "id": "3ac49964c4161b86",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ],
   "id": "79508dcfce404658",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Checking dataset columns**",
   "id": "9053c8ce29924edd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(X_train.columns)",
   "id": "dc8d58fb0b4949bb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Saving dataset as csv**",
   "id": "c9be63c90f0b3b2e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(type(X_train))\n",
    "print(type(y_train))"
   ],
   "id": "1f1a22921880c612",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# saving X train and y train as train csv \n",
    "train_set = pd.concat([X_train, y_train], axis=1)\n",
    "train_set.to_csv('train_set.csv', index=False)\n",
    "\n",
    "\n",
    "# saving X test and Y test as test csv \n",
    "test_set = pd.concat([X_test, y_test], axis=1)\n",
    "test_set.to_csv('test_set.csv', index=False)"
   ],
   "id": "f6eb3d52b8ade7de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# loading the CSV files and get the X train, Y train, X test, Y test \n",
    "import pandas as pd\n",
    "\n",
    "def load_and_split_data(train_file: str, test_file: str, target_column: str):\n",
    "    # Load the train and test sets from CSV\n",
    "    train_set = pd.read_csv(train_file)\n",
    "    test_set = pd.read_csv(test_file)\n",
    "\n",
    "    # Split into features and target\n",
    "    X_train = train_set.drop(columns=[target_column])\n",
    "    y_train = train_set[target_column]\n",
    "\n",
    "    X_test = test_set.drop(columns=[target_column])\n",
    "    y_test = test_set[target_column]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# Example usage:\n",
    "X_train, y_train, X_test, y_test = load_and_split_data('C:/Users/sdole/PycharmProjects/Movie_Rating_Project/train_tests_datasets/train_set.csv', \"C:/Users/sdole/PycharmProjects/Movie_Rating_Project/train_tests_datasets/test_set.csv\", target_column='IMDb Score')"
   ],
   "id": "205edf943774b3fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "y_train.shape",
   "id": "e801542d52048fba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_train.shape",
   "id": "c41a274fbd5cb44b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model Training",
   "id": "4b5cbdefcff400f8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ],
   "id": "9615d05f9abec38",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Default - Decision tree",
   "id": "ca91359fab66470a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# train a default tree \n",
    "default_tree = DecisionTreeRegressor(random_state=42)\n",
    "print(default_tree.get_params())\n",
    "default_tree.fit(X_train, y_train)\n",
    "\n",
    "# learned parameters value\n",
    "print(f\"Tree Depth: {default_tree.get_depth()}\")\n",
    "# Check the minimum number of samples in any leaf node\n",
    "print(f\"Minimum Samples in Leaf Nodes: {default_tree.get_n_leaves()}\")\n",
    "\n",
    "y_train_pred = default_tree.predict(X_train)\n",
    "train_MSE = MSE(y_train,y_train_pred)\n",
    "train_RMSE = train_MSE**(1/2)\n",
    "print(f'MSE on train set: {train_MSE}')\n",
    "print(f'RMSE on train set: {train_RMSE}')\n",
    "\n",
    "y_test_pred = default_tree.predict(X_test)\n",
    "test_MSE = MSE(y_test,y_test_pred)\n",
    "test_RMSE = test_MSE**(1/2)\n",
    "print(f'train MSE on test set: {test_MSE}')\n",
    "print(f'RMSE on test set: {test_RMSE}')"
   ],
   "id": "66a3c6c9a2644ea9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Access the tree structure\n",
    "tree = default_tree.tree_\n",
    "\n",
    "# Identify leaf nodes\n",
    "is_leaf = tree.children_left == -1\n",
    "print(is_leaf)\n",
    "# Get the number of samples in each leaf node\n",
    "samples_in_leaves = tree.n_node_samples[is_leaf]\n",
    "print(samples_in_leaves)\n",
    "# Calculate the mean number of samples per leaf\n",
    "mean_samples_per_leaf = np.mean(samples_in_leaves)\n",
    "\n",
    "print(f\"Mean number of samples per leaf: {mean_samples_per_leaf:.2f}\")"
   ],
   "id": "8bc2eb8be75cece4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# split only for plotting \n",
    "x_train_split, x_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "res = []\n",
    "samples_in_leaf = range(1, 100)\n",
    "\n",
    "\n",
    "\n",
    "for samples in samples_in_leaf:\n",
    "    print(f\"Evaluating min_samples_leaf={samples}\")\n",
    "    model = DecisionTreeRegressor(random_state=42, min_samples_leaf=samples)\n",
    "    model.fit(x_train_split, y_train_split)\n",
    "    \n",
    "    # Predict on training data\n",
    "    y_train_pred = model.predict(x_train_split)\n",
    "    train_MSE = MSE(y_train_split,y_train_pred)\n",
    "    train_RMSE = train_MSE**(1/2)\n",
    "    \n",
    "    # Predict on validation data\n",
    "    y_val_pred = model.predict(x_val)\n",
    "    val_MSE = MSE(y_val,y_val_pred)\n",
    "    val_RMSE = val_MSE**(1/2)\n",
    "\n",
    "    res.append({\n",
    "        'samples_in_a_leaf': samples, \n",
    "        'train_rmse': train_RMSE, \n",
    "        'val_rmse': val_RMSE\n",
    "    })\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "res = pd.DataFrame(res)\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(13, 4))\n",
    "plt.plot(res['samples_in_a_leaf'], res['train_rmse'], marker='o', markersize=4)\n",
    "plt.plot(res['samples_in_a_leaf'], res['val_rmse'], marker='o', markersize=4)\n",
    "plt.legend(['Train RMSE', 'Validation RMSE'])\n",
    "plt.xlabel('Min Samples in a Leaf')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('RMSE by Min samples leaf - Decision tree')\n",
    "plt.savefig('Min_Samples_in_a_Leaf.png', facecolor='white', edgecolor='white')\n",
    "plt.show()"
   ],
   "id": "2f5d401dd7416c4f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "res = []\n",
    "max_depth = range(1,52)\n",
    "\n",
    "\n",
    "\n",
    "for depth in max_depth:\n",
    "    print(f\"Evaluating min_samples_leaf={depth}\")\n",
    "    model = DecisionTreeRegressor(random_state=42, max_depth=depth)\n",
    "    model.fit(x_train_split, y_train_split)\n",
    "    \n",
    "    # Predict on training data\n",
    "    y_train_pred = model.predict(x_train_split)\n",
    "    train_MSE = MSE(y_train_split,y_train_pred)\n",
    "    train_RMSE = train_MSE**(1/2)\n",
    "    \n",
    "    # Predict on validation data\n",
    "    y_val_pred = model.predict(x_val)\n",
    "    val_MSE = MSE(y_val,y_val_pred)\n",
    "    val_RMSE = val_MSE**(1/2)\n",
    "\n",
    "    res.append({\n",
    "        'depth': depth, \n",
    "        'train_rmse': train_RMSE, \n",
    "        'val_rmse': val_RMSE\n",
    "    })\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "res = pd.DataFrame(res)\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(13, 4))\n",
    "plt.plot(res['depth'], res['train_rmse'], marker='o', markersize=4)\n",
    "plt.plot(res['depth'], res['val_rmse'], marker='o', markersize=4)\n",
    "plt.legend(['Train RMSE', 'Validation RMSE'])\n",
    "plt.xlabel('Depth')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('RMSE by Max depth - Decision tree')\n",
    "plt.savefig('max_depth_decision_tree.png', facecolor='white', edgecolor='white')\n",
    "plt.show()"
   ],
   "id": "631449ad9c37f9b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Hyperparameter tuning - Decision tree",
   "id": "9663477b6e35539f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Decision tree \n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "tree_model = DecisionTreeRegressor(random_state=42)\n",
    "param_grid = {\n",
    "    'min_samples_leaf': np.arange(10,60),\n",
    "    'max_depth': list(np.arange(10, 40)) + [None],\n",
    "}\n",
    "\n",
    "rand_search = RandomizedSearchCV(estimator=tree_model, param_distributions=param_grid, scoring='neg_mean_squared_error' , cv=kf, n_jobs=-1, refit=True, return_train_score=True, n_iter=600, random_state=42)\n",
    "rand_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model and its hyperparameters\n",
    "best_model = rand_search.best_estimator_\n",
    "best_hyperparams = rand_search.best_params_\n",
    "print(\"Best hyperparameters:\", best_hyperparams)\n",
    "\n",
    "# Predictions on the training set\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "train_mse = MSE(y_train, y_train_pred)\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "print(f\"Train set MSE: {train_mse:.3f}, RMSE: {train_rmse:.3f}\")\n",
    "\n",
    "# Predictions on the test set\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "test_mse = MSE(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "print(f\"Test set MSE: {test_mse:.3f}, RMSE: {test_rmse:.3f}\")\n",
    "\n",
    "\n",
    "# cv_results_\n",
    "cv_results = pd.DataFrame(rand_search.cv_results_)\n",
    "print(cv_results.columns)"
   ],
   "id": "453ac81ce829fc3a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# CV results\n",
    "cv_results = pd.DataFrame(rand_search.cv_results_)\n",
    "selected_columns = ['params', 'mean_train_score', 'mean_test_score', 'std_test_score', 'rank_test_score']\n",
    "df_selected = cv_results[selected_columns]\n",
    "\n",
    "# Display the CV results DataFrame\n",
    "print(df_selected)"
   ],
   "id": "41d12437ade0d68b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Adjusted plot_configurations function\n",
    "def plot_configurations(result_df, is_best, model_name):\n",
    "    if is_best:\n",
    "        best_10_df = result_df.sort_values(by='rank_test_score', ascending=True)\n",
    "        dataframe_to_plot = best_10_df.head(10)\n",
    "        filename = f'{model_name} - top 10 configurations.png'\n",
    "    else: \n",
    "        worst_10_df = result_df.sort_values(by='rank_test_score', ascending=False)\n",
    "        dataframe_to_plot = worst_10_df.head(10)\n",
    "        filename = f'{model_name} - worst 10 configurations.png'\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(18, 4))\n",
    "    \n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "    table = ax.table(cellText=dataframe_to_plot.values, colLabels=dataframe_to_plot.columns, cellLoc='center', loc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(16) \n",
    "    \n",
    "    table.auto_set_column_width([0, 1, 2]) \n",
    "    \n",
    "    # Set cell size\n",
    "    for key, cell in table.get_celld().items():\n",
    "        cell.set_width(0.35) \n",
    "        cell.set_height(0.15)\n",
    "    \n",
    "    # Save the table as an image\n",
    "    plt.savefig(filename, bbox_inches='tight', pad_inches=0.5)\n",
    "    plt.show()\n",
    "\n",
    "# Use the adjusted function to plot the 10 best and 10 worst configurations\n",
    "plot_configurations(result_df=df_selected, is_best=True, model_name='Decision Tree')\n",
    "plot_configurations(result_df=df_selected, is_best=False, model_name='Decision Tree')\n"
   ],
   "id": "3d95f2223c8e3597",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get feature importance\n",
    "feature_importance = best_model.feature_importances_\n",
    "\n",
    "# dataframe of feature importance\n",
    "feature_names = X_train.columns \n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importance\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "importance_df = importance_df[importance_df['Importance']>0]\n",
    "# Plot the feature importance\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "plt.gca().invert_yaxis() \n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance - Decision tree', fontweight='bold')\n",
    "plt.savefig('Feature Importance- Decision Tree.png', facecolor='white', edgecolor='white')\n",
    "plt.show()"
   ],
   "id": "13a9db4fa223ee68",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Default - Randon forest",
   "id": "8b1dea4b727cd9b9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# default model \n",
    "default_tree = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "\n",
    "print(default_tree.get_params())\n",
    "default_tree.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = default_tree.predict(X_train)\n",
    "train_MSE = MSE(y_train,y_train_pred)\n",
    "train_RMSE = train_MSE**(1/2)\n",
    "print(f'MSE on train set: {train_MSE}')\n",
    "print(f'RMSE on train set: {train_RMSE}')\n",
    "\n",
    "y_test_pred = default_tree.predict(X_test)\n",
    "test_MSE = MSE(y_test,y_test_pred)\n",
    "test_RMSE = test_MSE**(1/2)\n",
    "print(f'train MSE on test set: {test_MSE}')\n",
    "print(f'RMSE on test set: {test_RMSE}')\n",
    "\n",
    "\n",
    "# finding parameters values in default random forest\n",
    "num_trees = len(default_tree.estimators_)\n",
    "max_depths = []\n",
    "samples_per_leaf = []\n",
    "\n",
    "for tree in default_tree.estimators_:\n",
    "    max_depths.append(tree.tree_.max_depth)\n",
    "    \n",
    "    n_node_samples = tree.tree_.n_node_samples\n",
    "    is_leaf = tree.tree_.children_left == -1  \n",
    "    leaf_samples = n_node_samples[is_leaf]\n",
    "    samples_per_leaf.extend(leaf_samples)\n",
    "    \n",
    "print(f\"Average maximum depth: {sum(max_depths) / num_trees}\")\n",
    "print(f\"Mean samples per leaf: {np.mean(samples_per_leaf)}\")"
   ],
   "id": "672999a9bb39c8a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# split only for plotting \n",
    "x_train_split, x_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "res = []\n",
    "samples_in_leaf = range(1, 100)\n",
    "\n",
    "\n",
    "\n",
    "for samples in samples_in_leaf:\n",
    "    print(f\"Evaluating min_samples_leaf={samples}\")\n",
    "    model = RandomForestRegressor(random_state=42, min_samples_leaf=samples)\n",
    "    model.fit(x_train_split, y_train_split)\n",
    "    \n",
    "    # Predict on training data\n",
    "    y_train_pred = model.predict(x_train_split)\n",
    "    train_MSE = MSE(y_train_split,y_train_pred)\n",
    "    train_RMSE = train_MSE**(1/2)\n",
    "    \n",
    "    # Predict on validation data\n",
    "    y_val_pred = model.predict(x_val)\n",
    "    val_MSE = MSE(y_val,y_val_pred)\n",
    "    val_RMSE = val_MSE**(1/2)\n",
    "\n",
    "    res.append({\n",
    "        'samples_in_a_leaf': samples, \n",
    "        'train_rmse': train_RMSE, \n",
    "        'val_rmse': val_RMSE\n",
    "    })\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "res = pd.DataFrame(res)\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(13, 4))\n",
    "plt.plot(res['samples_in_a_leaf'], res['train_rmse'], marker='o', markersize=4)\n",
    "plt.plot(res['samples_in_a_leaf'], res['val_rmse'], marker='o', markersize=4)\n",
    "plt.legend(['Train RMSE', 'Validation RMSE'])\n",
    "plt.xlabel('Min Samples in a Leaf')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('RMSE by Min samples leaf - Decision tree')\n",
    "plt.savefig('Min_Samples_in_a_Leaf.png', facecolor='white', edgecolor='white')\n",
    "plt.show()"
   ],
   "id": "5fb919141baf0159",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "res = []\n",
    "max_depth = range(1,55)\n",
    "\n",
    "\n",
    "\n",
    "for depth in max_depth:\n",
    "    print(f\"Evaluating min_samples_leaf={depth}\")\n",
    "    model = RandomForestRegressor(random_state=42, max_depth=depth)\n",
    "    model.fit(x_train_split, y_train_split)\n",
    "    \n",
    "    # Predict on training data\n",
    "    y_train_pred = model.predict(x_train_split)\n",
    "    train_MSE = MSE(y_train_split,y_train_pred)\n",
    "    train_RMSE = train_MSE**(1/2)\n",
    "    \n",
    "    # Predict on validation data\n",
    "    y_val_pred = model.predict(x_val)\n",
    "    val_MSE = MSE(y_val,y_val_pred)\n",
    "    val_RMSE = val_MSE**(1/2)\n",
    "\n",
    "    res.append({\n",
    "        'depth': depth, \n",
    "        'train_rmse': train_RMSE, \n",
    "        'val_rmse': val_RMSE\n",
    "    })\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "res = pd.DataFrame(res)\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(13, 4))\n",
    "plt.plot(res['depth'], res['train_rmse'], marker='o', markersize=4)\n",
    "plt.plot(res['depth'], res['val_rmse'], marker='o', markersize=4)\n",
    "plt.legend(['Train RMSE', 'Validation RMSE'])\n",
    "plt.xlabel('Depth')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('RMSE by Max depth - Decision tree')\n",
    "plt.savefig('max_depth_decision_tree.png', facecolor='white', edgecolor='white')\n",
    "plt.show()"
   ],
   "id": "2810f83a0464df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# max depth \n",
    "res = []\n",
    "estimators_list = range(10,200)\n",
    "for estimators_number in estimators_list:\n",
    "    print(estimators_number)\n",
    "    model = RandomForestRegressor(random_state=42, n_jobs=-1, n_estimators=estimators_number)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on training data\n",
    "    y_train_pred = model.predict(x_train_split)\n",
    "    train_MSE = MSE(y_train_split,y_train_pred)\n",
    "    train_RMSE = train_MSE**(1/2)\n",
    "    \n",
    "    # Predict on validation data\n",
    "    y_val_pred = model.predict(x_val)\n",
    "    val_MSE = MSE(y_val,y_val_pred)\n",
    "    val_RMSE = val_MSE**(1/2)\n",
    "    \n",
    "    res.append({'n_estimators': estimators_number, \n",
    "                      'train_RMSE': train_RMSE, \n",
    "                      'val_RMSE': val_RMSE, \n",
    "                      })\n",
    " \n",
    " # Convert the list of results to a DataFrame\n",
    "res = pd.DataFrame(res)   \n",
    "# Plotting the results\n",
    "plt.figure(figsize=(13, 4))\n",
    "plt.plot(res['n_estimators'], res['train_RMSE'], marker='o', markersize=4)\n",
    "plt.plot(res['n_estimators'], res['val_RMSE'], marker='o', markersize=4)\n",
    "plt.legend(['Train RMSE', 'Validation RMSE'])\n",
    "plt.xlabel('number of estimators')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('RMSE by Estimators number', fontweight='bold')\n",
    "plt.savefig('number of estimators - forest.png', facecolor='white', edgecolor='white')\n",
    "plt.show()"
   ],
   "id": "f3a336fc2e7a191a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Hyperparameter tuning - Random Forest",
   "id": "a5f916295f39a4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Decision tree \n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "tree_model = RandomForestRegressor(random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,200],\n",
    "    'min_samples_leaf': np.arange(10,60),\n",
    "    'max_depth': list(np.arange(10, 40)) + [None],\n",
    "}\n",
    "\n",
    "rand_search = RandomizedSearchCV(estimator=tree_model, param_distributions=param_grid, scoring='neg_mean_squared_error' , cv=kf, n_jobs=-1, refit=True, return_train_score=True, n_iter=600, random_state=42)\n",
    "rand_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model and its hyperparameters\n",
    "best_model = rand_search.best_estimator_\n",
    "best_hyperparams = rand_search.best_params_\n",
    "print(\"Best hyperparameters:\", best_hyperparams)\n",
    "\n",
    "# Predictions on the training set\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "train_mse = MSE(y_train, y_train_pred)\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "print(f\"Train set MSE: {train_mse:.3f}, RMSE: {train_rmse:.3f}\")\n",
    "\n",
    "# Predictions on the test set\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "test_mse = MSE(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "print(f\"Test set MSE: {test_mse:.3f}, RMSE: {test_rmse:.3f}\")\n",
    "\n",
    "\n",
    "# cv_results_\n",
    "cv_results = pd.DataFrame(rand_search.cv_results_)\n",
    "print(cv_results.columns)"
   ],
   "id": "a4ea54cdc544a480",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# CV results\n",
    "cv_results = pd.DataFrame(rand_search.cv_results_)\n",
    "selected_columns = ['params', 'mean_train_score', 'mean_test_score', 'std_test_score', 'rank_test_score']\n",
    "df_selected = cv_results[selected_columns]\n",
    "\n",
    "# Display the CV results DataFrame\n",
    "print(df_selected)"
   ],
   "id": "2dfb7756935b7285",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Use the adjusted function to plot the 10 best and 10 worst configurations\n",
    "plot_configurations(result_df=df_selected, is_best=True, model_name='Random Forest')\n",
    "plot_configurations(result_df=df_selected, is_best=False, model_name='Random Forest')"
   ],
   "id": "def27859b8d092",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get feature importance\n",
    "feature_importance = best_model.feature_importances_\n",
    "\n",
    "# dataframe of feature importance\n",
    "feature_names = X_train.columns \n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importance\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "importance_df = importance_df[importance_df['Importance']>0]\n",
    "# Plot the feature importance\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "plt.gca().invert_yaxis() \n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance - Random Forest', fontweight='bold')\n",
    "plt.savefig('Feature Importance- Random Forest.png', facecolor='white', edgecolor='white')\n",
    "plt.show()"
   ],
   "id": "57582a53c0866ee7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Default - XGboost",
   "id": "73d4479006bc42dc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# default model \n",
    "default_tree = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "\n",
    "print(default_tree.get_params())\n",
    "default_tree.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = default_tree.predict(X_train)\n",
    "train_MSE = MSE(y_train,y_train_pred)\n",
    "train_RMSE = train_MSE**(1/2)\n",
    "print(f'MSE on train set: {train_MSE}')\n",
    "print(f'RMSE on train set: {train_RMSE}')\n",
    "\n",
    "y_test_pred = default_tree.predict(X_test)\n",
    "test_MSE = MSE(y_test,y_test_pred)\n",
    "test_RMSE = test_MSE**(1/2)\n",
    "print(f'train MSE on test set: {test_MSE}')\n",
    "print(f'RMSE on test set: {test_RMSE}')\n",
    "\n",
    "\n",
    "# finding parameters values in default\n",
    "num_trees = len(default_tree.estimators_)\n",
    "max_depths = []\n",
    "samples_per_leaf = []\n",
    "\n",
    "for tree in default_tree.estimators_[:, 0]: \n",
    "    max_depths.append(tree.tree_.max_depth)\n",
    "    \n",
    "    n_node_samples = tree.tree_.n_node_samples\n",
    "    is_leaf = tree.tree_.children_left == -1  \n",
    "    leaf_samples = n_node_samples[is_leaf]\n",
    "    samples_per_leaf.extend(leaf_samples)\n",
    "    \n",
    "print(f\"Average maximum depth: {sum(max_depths) / num_trees}\")\n",
    "print(f\"Mean samples per leaf: {np.mean(samples_per_leaf)}\")"
   ],
   "id": "603be515bb7de70b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# split only for plotting \n",
    "x_train_split, x_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "res = []\n",
    "n_estimators = range(1, 200)\n",
    "\n",
    "\n",
    "\n",
    "for estimator_num in n_estimators:\n",
    "    print(f\"Evaluating min_samples_leaf={estimator_num}\")\n",
    "    model = GradientBoostingRegressor(random_state=42, n_estimators=estimator_num)\n",
    "    model.fit(x_train_split, y_train_split)\n",
    "    \n",
    "    # Predict on training data\n",
    "    y_train_pred = model.predict(x_train_split)\n",
    "    train_MSE = MSE(y_train_split,y_train_pred)\n",
    "    train_RMSE = train_MSE**(1/2)\n",
    "    \n",
    "    # Predict on validation data\n",
    "    y_val_pred = model.predict(x_val)\n",
    "    val_MSE = MSE(y_val,y_val_pred)\n",
    "    val_RMSE = val_MSE**(1/2)\n",
    "\n",
    "    res.append({\n",
    "        'number_of_estimators': estimator_num, \n",
    "        'train_rmse': train_RMSE, \n",
    "        'val_rmse': val_RMSE\n",
    "    })\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "res = pd.DataFrame(res)\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(13, 4))\n",
    "plt.plot(res['number_of_estimators'], res['train_rmse'], marker='o', markersize=4)\n",
    "plt.plot(res['number_of_estimators'], res['val_rmse'], marker='o', markersize=4)\n",
    "plt.legend(['Train RMSE', 'Validation RMSE'])\n",
    "plt.xlabel('Number of Estimators')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('RMSE by estimators number - gradient Boosting', fontweight='bold')\n",
    "plt.savefig('number_of_estimators - XGBoost.png', facecolor='white', edgecolor='white')\n",
    "plt.show()"
   ],
   "id": "7587e509a9343817",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# split only for plotting \n",
    "\n",
    "res = []\n",
    "max_depth = range(1, 15)\n",
    "\n",
    "\n",
    "\n",
    "for depth in max_depth:\n",
    "    print(f\"Evaluating min_samples_leaf={depth}\")\n",
    "    model = GradientBoostingRegressor(random_state=42, max_depth=depth)\n",
    "    model.fit(x_train_split, y_train_split)\n",
    "    \n",
    "    # Predict on training data\n",
    "    y_train_pred = model.predict(x_train_split)\n",
    "    train_MSE = MSE(y_train_split,y_train_pred)\n",
    "    train_RMSE = train_MSE**(1/2)\n",
    "    \n",
    "    # Predict on validation data\n",
    "    y_val_pred = model.predict(x_val)\n",
    "    val_MSE = MSE(y_val,y_val_pred)\n",
    "    val_RMSE = val_MSE**(1/2)\n",
    "\n",
    "    res.append({\n",
    "        'depth': depth, \n",
    "        'train_rmse': train_RMSE, \n",
    "        'val_rmse': val_RMSE\n",
    "    })\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "res = pd.DataFrame(res)\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(13, 4))\n",
    "plt.plot(res['depth'], res['train_rmse'], marker='o', markersize=4)\n",
    "plt.plot(res['depth'], res['val_rmse'], marker='o', markersize=4)\n",
    "plt.legend(['Train RMSE', 'Validation RMSE'])\n",
    "plt.xlabel('depth')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('RMSE by depth - Gradient Boosting', fontweight='bold')\n",
    "plt.savefig('Max Depth - XGBoost.png', facecolor='white', edgecolor='white')\n",
    "plt.show()"
   ],
   "id": "a228297962824e46",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Hyperparameter tuning - XGboost ",
   "id": "270a32750f7f384f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Decision tree \n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "tree_model = GradientBoostingRegressor(random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': list(np.arange(10,50)),\n",
    "    'max_depth': [2,3,4],\n",
    "    'learning_rate': [0.01,0.05,0.1]\n",
    "    \n",
    "}\n",
    "\n",
    "rand_search = RandomizedSearchCV(estimator=tree_model, param_distributions=param_grid, scoring='neg_mean_squared_error' , cv=kf, n_jobs=-1, refit=True, return_train_score=True, n_iter=300, random_state=42)\n",
    "rand_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model and its hyperparameters\n",
    "best_model = rand_search.best_estimator_\n",
    "best_hyperparams = rand_search.best_params_\n",
    "print(\"Best hyperparameters:\", best_hyperparams)\n",
    "\n",
    "# Predictions on the training set\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "train_mse = MSE(y_train, y_train_pred)\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "print(f\"Train set MSE: {train_mse:.3f}, RMSE: {train_rmse:.3f}\")\n",
    "\n",
    "# Predictions on the test set\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "test_mse = MSE(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "print(f\"Test set MSE: {test_mse:.3f}, RMSE: {test_rmse:.3f}\")\n",
    "\n",
    "\n",
    "# cv_results_\n",
    "cv_results = pd.DataFrame(rand_search.cv_results_)\n",
    "print(cv_results.columns)"
   ],
   "id": "8502d64c4a3ae53c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# CV results\n",
    "cv_results = pd.DataFrame(rand_search.cv_results_)\n",
    "selected_columns = ['params', 'mean_train_score', 'mean_test_score', 'std_test_score', 'rank_test_score']\n",
    "df_selected = cv_results[selected_columns]\n",
    "\n",
    "# Display the CV results DataFrame\n",
    "print(df_selected)"
   ],
   "id": "91320e099a766fa7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Use the adjusted function to plot the 10 best and 10 worst configurations\n",
    "plot_configurations(result_df=df_selected, is_best=True, model_name='Gradient Boosting')\n",
    "plot_configurations(result_df=df_selected, is_best=False, model_name='Gradient Boosting')"
   ],
   "id": "55eca8c4700e11bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get feature importance\n",
    "feature_importance = best_model.feature_importances_\n",
    "\n",
    "# dataframe of feature importance\n",
    "feature_names = X_train.columns \n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importance\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "importance_df = importance_df[importance_df['Importance']>0]\n",
    "# Plot the feature importance\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "plt.gca().invert_yaxis() \n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance - Gradient Boosting', fontweight='bold')\n",
    "plt.savefig('Feature Importance- Gradient Boosting', facecolor='white', edgecolor='white')\n",
    "plt.show()"
   ],
   "id": "1f99f812beac98e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b35957788d3e3f87",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
